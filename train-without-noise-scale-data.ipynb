{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = \"../UXO_protected/+BTInvertPY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cmap\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import Normalize\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import uxo_utils\n",
    "from uxo_utils import (\n",
    "    SensorInfo, Model, preCalcLoopCorners, FModParam, \n",
    "    forwardWithQ, sensorCoords2RxCoords, hprimary, formQmatrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['font.size'] = 14\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sensor info and ordnance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorinfo = uxo_utils.load_sensor_info()\n",
    "ordnance = uxo_utils.load_ordnance_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordnance.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up survey parameters\n",
    "- x is cross-line\n",
    "- y is inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntx = len(sensorinfo.transmitters)\n",
    "ymax = 3. \n",
    "y_spacing = 0.2\n",
    "dy = y_spacing / ntx\n",
    "nloc = int(ymax/dy)\n",
    "ncycles = int(nloc/ntx)\n",
    "\n",
    "y = np.linspace(0, ymax-dy, nloc)\n",
    "x = np.zeros(nloc)\n",
    "z = 0.28 * np.ones(nloc)\n",
    "\n",
    "pitch = np.zeros(nloc)\n",
    "roll = np.zeros(nloc)\n",
    "yaw = np.zeros(nloc)  # moving north (sensor in typical orientation)\n",
    "\n",
    "txnum = np.kron(np.ones(ncycles), np.arange(ntx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sensor location coordinates to Rx locations\n",
    "pos, mnum = sensorCoords2RxCoords(\n",
    "    sensorinfo=sensorinfo,\n",
    "    x = x, \n",
    "    y = y, \n",
    "    z = z, \n",
    "    pitch = pitch, \n",
    "    roll = roll, \n",
    "    yaw = yaw,\n",
    "    txnum = txnum\n",
    ")\n",
    "\n",
    "pitch = np.concatenate([np.tile(x,pos[i].shape[0]) for i,x in enumerate(pitch)])\n",
    "roll = np.concatenate([np.tile(x,pos[i].shape[0]) for i,x in enumerate(roll)])\n",
    "yaw = np.concatenate([np.tile(x,pos[i].shape[0]) for i,x in enumerate(yaw)])\n",
    "pos = np.concatenate(pos,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(pos[:, i].min(), pos[:, i].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ordnance objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ordnance[\"ISO Small\"][\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_me = {\n",
    "    \"ISO Small\": 1,\n",
    "    \"30mm\": 1\n",
    "}\n",
    "fig, ax = plt.subplots(len(plot_me.keys()), 2, figsize=(10, 4*len(plot_me.keys())))\n",
    "\n",
    "for i, key in enumerate(plot_me.keys()):\n",
    "    for l in [\"L1\", \"L2\", \"L3\"]:\n",
    "        L = ordnance[key][l][plot_me[key]]\n",
    "        ax[i, 0].plot(times, L, label=l)\n",
    "        ax[i, 1].loglog(times, L, label=l)\n",
    "\n",
    "    for a in ax[i, :]:\n",
    "        a.set_title(f\"{key}, index: {1}\")\n",
    "        a.grid(which=\"both\")\n",
    "        a.legend()\n",
    "        a.set_xlabel(\"time (ms)\")\n",
    "        a.set_ylim([1e-3, 3])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ranges of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range_iso_small = np.r_[0.2, 0.7]\n",
    "depth_range_30mm = np.r_[0.1, 0.5]\n",
    "\n",
    "x_range = np.r_[-1.25, 1.25]\n",
    "y_range = np.r_[0., ymax]\n",
    "\n",
    "yaw_range = np.r_[0, 2*np.pi]\n",
    "pitch_range = np.r_[0, 2*np.pi]\n",
    "roll_range = np.r_[0, 2*np.pi]\n",
    "\n",
    "def generate_random_variables(n, bounds):\n",
    "    return bounds.min() + (bounds.max() - bounds.min()) * np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 2048*2 #*4\n",
    "ntest = 1024\n",
    "nvalid = 1024\n",
    "\n",
    "class_dict = {\n",
    "    0: \"not TOI\",\n",
    "    1: \"ISO Small\",\n",
    "    2: \"30mm\"\n",
    "}\n",
    "n_class = len(class_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.random.choice(n_class, ntrain)\n",
    "labels_test = np.random.choice(n_class, ntest)\n",
    "labels_valid = np.random.choice(n_class, nvalid)\n",
    "\n",
    "def generate_parameters(labels):\n",
    "    n = len(labels)\n",
    "    i0 = labels == 0\n",
    "    i1 = labels == 1\n",
    "    i2 = labels == 2\n",
    "    \n",
    "    depths = np.zeros(n)\n",
    "    depths[i1] = generate_random_variables(i1.sum(), depth_range_iso_small)\n",
    "    depths[i2] = generate_random_variables(i2.sum(), depth_range_30mm)\n",
    "    \n",
    "    x = generate_random_variables(n, x_range)\n",
    "    y = generate_random_variables(n, y_range)\n",
    "    z = -depths\n",
    "    \n",
    "    yaw = generate_random_variables(n, yaw_range)\n",
    "    pitch = generate_random_variables(n, pitch_range)\n",
    "    roll = generate_random_variables(n, roll_range)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"label\": labels,\n",
    "        \"depth\": depths,\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"z\": z,\n",
    "        \"yaw\": yaw,\n",
    "        \"pitch\": pitch,\n",
    "        \"roll\": roll\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = generate_parameters(labels_train) \n",
    "params_test = generate_parameters(labels_test) \n",
    "params_valid = generate_parameters(labels_valid) \n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(18, 8))\n",
    "ax = ax.flatten()\n",
    "\n",
    "i = 0\n",
    "for key, val in params_train.items():\n",
    "    for j in range(3):\n",
    "        if key != \"label\" and j ==0: \n",
    "            pass  # these parameters are irrelevant if there is no object\n",
    "        else:\n",
    "            inds = labels_train == j\n",
    "            ax[i].hist(val[inds], 10, color=f\"C{j}\", alpha=0.6)\n",
    "    ax[i].set_title(key)\n",
    "    i += 1\n",
    "\n",
    "ax[0].legend([class_dict[0], class_dict[1], class_dict[2]])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up forward simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figuring out where all of the vertices are in coordinate system -- gives us location of vertices \n",
    "Tx_indices_rot, Rx_indices_rot = preCalcLoopCorners(\n",
    "    sensorinfo=sensorinfo, mnum=mnum, rlist=pos, pitch=pitch, roll=roll, yaw=yaw\n",
    ") \n",
    "\n",
    "# convienence object for inputs to fwd modelling \n",
    "st = FModParam(sensorinfo, pos, mnum, times, Tx_indices_rot, Rx_indices_rot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(parameters, st=st, mnum=mnum, ncycles=ncycles):\n",
    "    data = []\n",
    "    for i, l in enumerate(parameters[\"label\"]):\n",
    "        if l == 0:\n",
    "            # this can later be replaced with random noise or other structured but uninteresting signal\n",
    "            V = np.zeros((pos.shape[0], len(times)))\n",
    "        else: \n",
    "            xyz = np.r_[parameters[\"x\"][i], parameters[\"y\"][i], parameters[\"z\"][i]]\n",
    "            ypr = np.r_[parameters[\"yaw\"][i], parameters[\"pitch\"][i], parameters[\"roll\"][i]]\n",
    "            L3 = ordnance[class_dict[l]][\"L3\"][1]\n",
    "            L2 = ordnance[class_dict[l]][\"L2\"][1]\n",
    "            L1 = ordnance[class_dict[l]][\"L1\"][1]\n",
    "            \n",
    "            mod = Model(xyz=xyz, gba=ypr, l3=L3, l2=L2, l1=L1, times=times)\n",
    "            V = forwardWithQ(mod, st) # nT/s (some version of db/dt)\n",
    "        V = V.reshape(ncycles, mnum.max()+1, len(times))\n",
    "        V = np.swapaxes(V, 0, 1)\n",
    "        data.append(V)\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_train = run_simulations(params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_test = run_simulations(params_test)\n",
    "data_valid = run_simulations(params_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scaling = (times)\n",
    "time_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_train = [d*time_scaling for d in data_train]\n",
    "scaled_data_test = [d*time_scaling for d in data_test]\n",
    "scaled_data_valid = [d*time_scaling for d in data_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.swapaxes(pos.reshape(ncycles, mnum.max()+1, 3), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dind = 3\n",
    "d = data_train[dind]\n",
    "\n",
    "print(f\"class: {class_dict[labels_train[dind]]}, data shape: {d.shape}\")\n",
    "\n",
    "params_train.iloc[dind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx_num, rx_num, rx_comp, rxcube\n",
    "sensor_table = sensorinfo.measNum2TxRxRxcCube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sensor_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nrx = 11\n",
    "fig, ax = plt.subplots(nrx, 3, figsize=(11, 1.5*nrx))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "plot_tx = 0\n",
    "tx_inds = (sensor_table[:, 0] == plot_tx)\n",
    "\n",
    "cm = plt.get_cmap('magma')\n",
    "c_norm = Normalize(vmin=times.min(), vmax=times.max())\n",
    "scalar_map = cmap.ScalarMappable(norm=c_norm, cmap=cm)\n",
    "scalar_map.set_array([])\n",
    "\n",
    "d = scaled_data_train[dind]\n",
    "\n",
    "for rx in range(nrx):\n",
    "    ii = tx_inds & (sensor_table[:, 3] == rx)\n",
    "    for a, comp in zip(ax[rx, :], [0, 1, 2]):\n",
    "        mnumind = np.where( ii & (sensor_table[:, 2] == comp))[0][0]\n",
    "        for t in range(len(times)):\n",
    "            a.plot(\n",
    "                pos[mnumind, :, 1], d[mnumind, :, t], \n",
    "                color=scalar_map.to_rgba(times[t]), marker=\".\", lw=0.5, alpha=0.4, ms=3\n",
    "            )\n",
    "\n",
    "        a.grid(which=\"both\", alpha=0.4)\n",
    "        if rx < nrx-1:\n",
    "            a.set_xticklabels('')\n",
    "        else:\n",
    "            a.set_xlabel(\"along-line (m)\")\n",
    "        \n",
    "        if rx == 0:\n",
    "            if comp == 0:\n",
    "                a.set_title(\"x-component\")\n",
    "            elif comp == 1:\n",
    "                a.set_title(\"y-component\")\n",
    "            elif comp == 2:\n",
    "                a.set_title(\"z-component\")\n",
    "        \n",
    "        if comp == 0:\n",
    "            a.set_ylabel(f\"rx {rx}\")\n",
    "            a.yaxis.set_label_coords(-0.3, 0.5)\n",
    "            \n",
    "# plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.18, 0.07, 0.65, 0.005])\n",
    "cb = plt.colorbar(scalar_map, cbar_ax, orientation=\"horizontal\")\n",
    "cb.set_label('time (ms)')\n",
    "\n",
    "fig.suptitle(f\"Transmitter {plot_tx+1}, Target {dind}: {class_dict[labels_train[dind]]}\", y=0.92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrx = 11\n",
    "fig, ax = plt.subplots(nrx, 3, figsize=(11, 1.5*nrx))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "plot_tx = 0\n",
    "tx_inds = (sensor_table[:, 0] == plot_tx)\n",
    "\n",
    "d = scaled_data_train[dind]\n",
    "\n",
    "for rx in range(nrx):\n",
    "    ii = tx_inds & (sensor_table[:, 3] == rx)\n",
    "    plotme = d[mnumind, :, :].T\n",
    "    for a, comp in zip(ax[rx, :], [0, 1, 2]):\n",
    "        mnumind = np.where( ii & (sensor_table[:, 2] == comp))[0][0]\n",
    "        out = a.pcolormesh(\n",
    "            pos[mnumind, :, 1], times, \n",
    "            plotme, cmap=\"RdBu\", vmin=-(np.abs(plotme.max())).max(), vmax=(np.abs(plotme.max())).max()\n",
    "        )\n",
    "\n",
    "#         a.grid(which=\"both\", alpha=0.4)\n",
    "#         a.set_aspect(1)\n",
    "        if rx < nrx-1:\n",
    "            a.set_xticklabels('')\n",
    "        else:\n",
    "            a.set_xlabel(\"along-line (m)\")\n",
    "        \n",
    "        if rx == 0:\n",
    "            if comp == 0:\n",
    "                a.set_title(\"x-component\")\n",
    "            elif comp == 1:\n",
    "                a.set_title(\"y-component\")\n",
    "            elif comp == 2:\n",
    "                a.set_title(\"z-component\")\n",
    "        \n",
    "        if comp == 0:\n",
    "            a.set_ylabel(f\"rx {rx}\")\n",
    "            a.yaxis.set_label_coords(-0.3, 0.5)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.18, 0.07, 0.65, 0.005])\n",
    "cb = plt.colorbar(out, cbar_ax, orientation=\"horizontal\")\n",
    "cb.set_label('signal')\n",
    "\n",
    "fig.suptitle(f\"Transmitter {plot_tx+1}, Target {dind}: {class_dict[labels_train[dind]]}\", y=0.92)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a ConvNet classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_scaled = True\n",
    "if use_scaled is True: \n",
    "    X_train = torch.from_numpy(np.float32(np.stack(scaled_data_train, axis=0)))\n",
    "    X_test = torch.from_numpy(np.float32(np.stack(scaled_data_test, axis=0)))\n",
    "    X_valid = torch.from_numpy(np.float32(np.stack(scaled_data_valid, axis=0)))\n",
    "\n",
    "elif use_scaled is False: \n",
    "    X_train = torch.from_numpy(np.float32(np.stack(data_train, axis=0)))\n",
    "    X_test = torch.from_numpy(np.float32(np.stack(data_test, axis=0)))\n",
    "    X_valid = torch.from_numpy(np.float32(np.stack(data_valid, axis=0)))\n",
    "\n",
    "\n",
    "C_train = torch.from_numpy(np.float32(labels_train)).long()\n",
    "C_test = torch.from_numpy(np.float32(labels_test)).long()\n",
    "C_valid = torch.from_numpy(np.float32(labels_valid)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, network_geometry):\n",
    "        super().__init__()\n",
    "        self.network_geometry=network_geometry\n",
    "        self.nt = len(network_geometry)\n",
    "    \n",
    "    def forward(self, X, K, batch_norm):  \n",
    "        for i, Ki, bn in zip(range(self.nt), K, batch_norm):\n",
    "            z = functional.conv2d(X, Ki, stride=1, padding=1)\n",
    "            z = bn(z)\n",
    "            z = functional.relu(z)\n",
    "            z = functional.max_pool2d(z, 3, stride=1, padding=1)\n",
    "            X = z\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 165\n",
    "n_class = 3\n",
    "layer_geometries = [in_channels, 33, 11] #11, 11, 11]\n",
    "nlayers = len(layer_geometries)\n",
    "initial_scaling = 1e-3\n",
    "\n",
    "width = nloc//ntx\n",
    "ntimes = len(times)\n",
    "\n",
    "# initialize K's and batch normalizations\n",
    "K = []\n",
    "batch_norm = []\n",
    "bias = []\n",
    "for i in range(nlayers-1):\n",
    "    n_in = layer_geometries[i]\n",
    "    n_out = layer_geometries[i+1]\n",
    "    Ki = nn.Parameter(torch.Tensor(n_out, n_in, 3, 3))\n",
    "    Ki.data = torch.randn(n_out, n_in, 3, 3)  * initial_scaling\n",
    "    K.append(Ki)\n",
    "    \n",
    "    batch_norm.append(nn.BatchNorm2d(n_out))\n",
    "\n",
    "# initialize classifier W\n",
    "W = nn.Parameter(torch.Tensor(layer_geometries[-1]*width*ntimes, n_class))\n",
    "W.data = torch.randn(layer_geometries[-1]*width*ntimes, n_class)*initial_scaling\n",
    "\n",
    "b = nn.Parameter(torch.randn(n_class)*initial_scaling, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet(layer_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the network\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = net(X_train, K, batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "def misfit(X, W, b, C):\n",
    "    n = W.shape\n",
    "    X = X.view(-1, n[0])\n",
    "    S = torch.matmul(X, W) + b.unsqueeze(0)\n",
    "\n",
    "    probs = functional.softmax(S, dim=1)\n",
    "    return loss_func(S, C), probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parout = (\n",
    "    np.sum(np.array([np.prod(Ki.shape) for Ki in K])) + np.prod(W.shape)\n",
    ")\n",
    "\n",
    "print('Total number of parameters', n_parout)\n",
    "print('Total number of data', labels_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(S, labels):\n",
    "    _, predicted = torch.max(S, dim=1)\n",
    "    total = np.prod(labels.size())\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, probs = misfit(out, W, b, C_train)\n",
    "print('Initial loss = ', loss.detach().numpy())    \n",
    "print(f'Check:log({n_class}) = ', np.log(n_class))\n",
    "\n",
    "print(f\"\\nInitial accuracy: {accuracy(probs, C_train)}\")\n",
    "print(f\"Check random    : {1/n_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(\n",
    "    [{'params': W}, {'params':b}, {'params': K}], \n",
    "    lr = 1e0, momentum=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss_train = []\n",
    "running_loss_test = []\n",
    "running_accuracy_train = []\n",
    "running_accuracy_test = []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    g = 0.0\n",
    "    loss = 0.0\n",
    "    ind = 0\n",
    "    \n",
    "    while ind < X_train.shape[1]:    \n",
    "        optimizer.zero_grad()\n",
    "        # get the inputs\n",
    "        inputs = X_train[ind:ind+batch_size, :, :, :]\n",
    "        labels = C_train[ind:ind+batch_size]\n",
    "\n",
    "        # forward \n",
    "        x = net(inputs, K, batch_norm)\n",
    "        lossi, _ = misfit(x, W, b, labels)\n",
    "        if i==0:\n",
    "            loss = lossi\n",
    "        else:\n",
    "            loss += lossi\n",
    "        lossi.backward()\n",
    "        optimizer.step()\n",
    "        ind += batch_size\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        xtest = net(X_test, K, batch_norm)\n",
    "        loss_test, probs_test = misfit(xtest, W, b, C_test)\n",
    "\n",
    "        xtrain = net(X_train, K, batch_norm)\n",
    "        loss_train, probs_train = misfit(xtrain, W, b, C_train)\n",
    "\n",
    "        accuracy_train = accuracy(probs_train, C_train)\n",
    "        accuracy_test = accuracy(probs_test, C_test)\n",
    "\n",
    "        g = torch.norm(W.grad) + sum([torch.norm(Ki.grad) for Ki in K]) + torch.norm(b.grad)\n",
    "\n",
    "        running_loss_train.append(loss_train)\n",
    "        running_loss_test.append(loss_test)\n",
    "        running_accuracy_train.append(accuracy_train)\n",
    "        running_accuracy_test.append(accuracy_test)\n",
    "    \n",
    "        if np.mod(epoch, 10) == 0: \n",
    "            print(f'{epoch:3d}  {loss:2.3e}  {loss_test:2.3e} {g:2.3e} {accuracy_train:0.3f}  {accuracy_test:0.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "x_train_net = net(X_train, K, batch_norm)\n",
    "_, probs_train = misfit(x_train_net, W, b, C_train)\n",
    "_, pred_train = torch.max(probs_train, dim=1)\n",
    "\n",
    "# test set\n",
    "x_test_net = net(X_test, K, batch_norm)\n",
    "_, probs_test = misfit(x_test_net, W, b, C_test)\n",
    "_, pred_test = torch.max(probs_test, dim=1)\n",
    "\n",
    "# validation set\n",
    "x_valid_net = net(X_valid, K, batch_norm)\n",
    "_, probs_valid = misfit(x_valid_net, W, b, C_valid)\n",
    "_, pred_valid = torch.max(probs_valid, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training accuracy: {accuracy(probs_train, C_train):1.4f}\")\n",
    "print(f\"test accuracy    : {accuracy(probs_test, C_test):1.4f}\")\n",
    "print(f\"valid accuracy   : {accuracy(probs_valid, C_valid):1.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see where it struggled\n",
    "\n",
    "def get_mislabeled(S, labels):\n",
    "    _, predicted = torch.max(S, dim=1)\n",
    "    incorrect = (predicted != labels)\n",
    "    return incorrect.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_train = get_mislabeled(probs_train, C_train)\n",
    "mislabeled_test = get_mislabeled(probs_test, C_test)\n",
    "mislabeled_valid = get_mislabeled(probs_valid, C_valid)\n",
    "\n",
    "_, pred_labels_train = torch.max(probs_train, dim=1)\n",
    "_, pred_labels_test = torch.max(probs_test, dim=1)\n",
    "_, pred_labels_valid = torch.max(probs_valid, dim=1)\n",
    "\n",
    "print(f\"Mislabeled. train: {mislabeled_train.sum()}, test: {mislabeled_test.sum()}, valid: {mislabeled_valid.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true_labels, predicted_labels):\n",
    "    n = len(np.unique(true_labels))\n",
    "    M = np.zeros((n, n), dtype=int)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            M[i, j] = sum((true_labels == i) & (predicted_labels == j))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(C_train, pred_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(C_test, pred_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(C_valid, pred_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds, vals = torch.max(probs_valid[mislabeled_valid, :], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(1/len(data_train) * np.array(running_loss_train), label=\"training\")\n",
    "ax[0].plot(1/len(data_test) * np.array(running_loss_test), label=\"test\")\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(running_accuracy_train, label=\"training\")\n",
    "ax[1].plot(running_accuracy_test, label=\"test\")\n",
    "ax[1].set_title(\"accuracy\")\n",
    "\n",
    "for a in ax:\n",
    "    a.grid(which=\"both\")\n",
    "    a.set_xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at features in network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "\n",
    "print(probs_train[ind, :])\n",
    "print(f\"class: {class_dict[labels_train[ind]]}\")\n",
    "\n",
    "params_train.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0 = []\n",
    "Z1 = []\n",
    "Z2 = []\n",
    "Z3 = []\n",
    "with torch.no_grad():\n",
    "    X = X_train[ind:ind+1, :, :, :]\n",
    "    for Ki, bn in zip(K, batch_norm):\n",
    "        z0 = functional.conv2d(X, Ki, stride=1, padding=1)\n",
    "        z1 = bn(z0)\n",
    "        z2 = functional.relu(z1)\n",
    "        z3 = functional.max_pool2d(z2, 3, stride=1, padding=1)\n",
    "        X = z3\n",
    "        Z0.append(z0)\n",
    "        Z1.append(z1)\n",
    "        Z2.append(z2)\n",
    "        Z3.append(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colorbar(plt.pcolormesh(K[1][:, :, 2, 1].data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(33, 11, figsize = (11*0.5, 33*0.5))\n",
    "\n",
    "plotme = K[1].detach()\n",
    "vmax=np.abs(plotme.flatten()).max()\n",
    "vmin=-vmax\n",
    "print(vmin, vmax)\n",
    "\n",
    "for i in range(33):\n",
    "    for j in range(11):\n",
    "        a = ax[i, j]\n",
    "        a.set_xticklabels('')\n",
    "        a.set_yticklabels('')\n",
    "        a.pcolormesh(plotme[j, i, :, :], vmin=vmin, vmax=vmax, cmap=\"RdBu\")\n",
    "# K[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = 33\n",
    "fig, ax = plt.subplots(11, 3, figsize=(11, 1.5*11))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "cm = plt.get_cmap('magma')\n",
    "c_norm = Normalize(vmin=times.min(), vmax=times.max())\n",
    "scalar_map = cmap.ScalarMappable(norm=c_norm, cmap=cm)\n",
    "scalar_map.set_array([])\n",
    "\n",
    "plot_me = Z3[0][0, :, :, :]\n",
    "\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    for t in range(len(times)):\n",
    "        a.plot(\n",
    "            plot_me[i, :, t], \n",
    "            color=scalar_map.to_rgba(times[t]), marker=\".\", lw=0.5, alpha=0.4, ms=3\n",
    "        )\n",
    "\n",
    "        a.grid(which=\"both\", alpha=0.4)\n",
    "        if rx < nrx-1:\n",
    "            a.set_xticklabels('')\n",
    "            \n",
    "# plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.18, 0.07, 0.65, 0.005])\n",
    "cb = plt.colorbar(scalar_map, cbar_ax, orientation=\"horizontal\")\n",
    "cb.set_label('time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = 11\n",
    "fig, ax = plt.subplots(11, 1, figsize=(4, 1.5*11))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "cm = plt.get_cmap('magma')\n",
    "c_norm = Normalize(vmin=times.min(), vmax=times.max())\n",
    "scalar_map = cmap.ScalarMappable(norm=c_norm, cmap=cm)\n",
    "scalar_map.set_array([])\n",
    "\n",
    "plot_me = Z3[1][0, :, :, :]\n",
    "\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    for t in range(len(times)):\n",
    "        a.plot(\n",
    "            plot_me[i, :, t], \n",
    "            color=scalar_map.to_rgba(times[t]), marker=\".\", lw=0.5, alpha=0.4, ms=3\n",
    "        )\n",
    "\n",
    "        a.grid(which=\"both\", alpha=0.4)\n",
    "        if rx < nrx-1:\n",
    "            a.set_xticklabels('')\n",
    "            \n",
    "# plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.18, 0.07, 0.65, 0.005])\n",
    "cb = plt.colorbar(scalar_map, cbar_ax, orientation=\"horizontal\")\n",
    "cb.set_label('time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_plot = []\n",
    "with torch.no_grad():\n",
    "    for i in range(n_class):\n",
    "        w_plot.append(W[:, i].view(Z3[1].shape).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = 11\n",
    "fig, ax = plt.subplots(11, 3, figsize=(11, 1.5*11))\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "cm = plt.get_cmap('magma')\n",
    "c_norm = Normalize(vmin=times.min(), vmax=times.max())\n",
    "scalar_map = cmap.ScalarMappable(norm=c_norm, cmap=cm)\n",
    "scalar_map.set_array([])\n",
    "\n",
    "for ii, w in enumerate(w_plot):\n",
    "    for i, a in enumerate(ax[:, ii]):\n",
    "        for t in range(len(times)):\n",
    "            a.plot(\n",
    "                w[0, i, :, t], \n",
    "                color=scalar_map.to_rgba(times[t]), marker=\".\", lw=0.5, alpha=0.4, ms=3\n",
    "            )\n",
    "\n",
    "            a.grid(which=\"both\", alpha=0.4)\n",
    "            if rx < nrx-1:\n",
    "                a.set_xticklabels('')\n",
    "            \n",
    "# plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.18, 0.07, 0.65, 0.005])\n",
    "cb = plt.colorbar(scalar_map, cbar_ax, orientation=\"horizontal\")\n",
    "cb.set_label('time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a line of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax_profile = 30\n",
    "nloc_profile = int(ymax_profile/dy)\n",
    "ncycles_profile = int(nloc_profile/ntx)\n",
    "\n",
    "y_profile = np.linspace(0, ymax_profile-dy, nloc_profile)\n",
    "x_profile = np.zeros(nloc_profile)\n",
    "z_profile = 0.28 * np.ones(nloc_profile)\n",
    "\n",
    "pitch_profile = np.zeros(nloc_profile)\n",
    "roll_profile = np.zeros(nloc_profile)\n",
    "yaw_profile = np.zeros(nloc_profile)  # moving north (sensor in typical orientation)\n",
    "\n",
    "txnum_profile = np.kron(np.ones(ncycles_profile), np.arange(ntx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sensor location coordinates to Rx locations\n",
    "pos_profile, mnum_profile = sensorCoords2RxCoords(\n",
    "    sensorinfo=sensorinfo,\n",
    "    x = x_profile, \n",
    "    y = y_profile, \n",
    "    z = z_profile, \n",
    "    pitch = pitch_profile, \n",
    "    roll = roll_profile, \n",
    "    yaw = yaw_profile,\n",
    "    txnum = txnum_profile\n",
    ")\n",
    "\n",
    "pitch_profile = np.concatenate([np.tile(x,pos_profile[i].shape[0]) for i,x in enumerate(pitch_profile)])\n",
    "roll_profile = np.concatenate([np.tile(x,pos_profile[i].shape[0]) for i,x in enumerate(roll_profile)])\n",
    "yaw_profile = np.concatenate([np.tile(x,pos_profile[i].shape[0]) for i,x in enumerate(yaw_profile)])\n",
    "pos_profile = np.concatenate(pos_profile,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_profile = np.r_[0.1, 0.25, 0.5, 0.2, 0.45, 0.7]\n",
    "params_profile = pd.DataFrame({\n",
    "    \"label\": [2, 2, 2, 1, 1, 1],\n",
    "    \"depth\": depths_profile,\n",
    "    \"x\": np.r_[0, 0, 0, 0, 0, 0],\n",
    "    \"y\": np.r_[2, 5, 10, 15, 20, 25],\n",
    "    \"z\": -depths_profile,\n",
    "    \"yaw\": np.r_[0, np.pi/4, np.pi, 0, np.pi/4, np.pi/2],\n",
    "    \"pitch\": np.r_[0, 0, 0, 0, 0, 0],\n",
    "    \"roll\": np.r_[0, 0, 0, 0, 0, 0]\n",
    "})\n",
    "params_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figuring out where all of the vertices are in coordinate system -- gives us location of vertices \n",
    "Tx_indices_rot_profile, Rx_indices_rot_profile = preCalcLoopCorners(\n",
    "    sensorinfo=sensorinfo, mnum=mnum_profile, rlist=pos_profile, pitch=pitch_profile, roll=roll_profile, yaw=yaw_profile\n",
    ") \n",
    "\n",
    "# convienence object for inputs to fwd modelling \n",
    "st_profile = FModParam(sensorinfo, pos_profile, mnum_profile, times, Tx_indices_rot_profile, Rx_indices_rot_profile)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profile = run_simulations(params_profile, st=st_profile, mnum=mnum_profile, ncycles=ncycles_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profile[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_profile = pos_profile[:, 0].reshape((165, ncycles_profile), order=\"F\")\n",
    "Y_profile = pos_profile[:, 1].reshape((165, ncycles_profile), order=\"F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_profile = sum(data_profile)\n",
    "D_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width_profile = int(ymax/y_spacing)\n",
    "w_step_profile = 5\n",
    "n_windows_profile = (X_profile.shape[1]-window_width_profile)//w_step_profile\n",
    "print(n_windows_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = D_profile.shape\n",
    "net_data_profile = np.zeros((n_windows_profile, n[0], window_width_profile, n[2]))\n",
    "net_y_profile = np.zeros((n_windows_profile, n[0], window_width_profile))\n",
    "net_x_profile = np.zeros((n_windows_profile, n[0], window_width_profile))\n",
    "\n",
    "for i in range(n_windows_profile):\n",
    "    inds = slice(i*w_step_profile,i*w_step_profile+window_width_profile)\n",
    "    net_x_profile[i, :, :] = X_profile[:, inds]\n",
    "    net_y_profile[i, :, :] = Y_profile[:, inds]\n",
    "    net_data_profile[i, :, :, :] = D_profile[:, inds, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_scaled is True:\n",
    "    net_data_profile_torch = torch.from_numpy(np.float32(net_data_profile*time_scaling))\n",
    "else:\n",
    "    net_data_profile_torch = torch.from_numpy(np.float32(net_data_profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_field = net(net_data_profile_torch, K, batch_norm)\n",
    "    n = W.shape\n",
    "    S = torch.matmul(out_field.view(-1, n[0]), W)\n",
    "    probs_profile = functional.softmax(S, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels_profile = torch.max(probs_profile, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_profile[mnum, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnum_plot = 12\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "ordnance_labels = [\n",
    "    Line2D(\n",
    "        [0], [0], marker='o', color=\"w\", \n",
    "        markerfacecolor=f'C{int(key)}', markeredgecolor=f'C{int(key)}', \n",
    "        label=value\n",
    "    ) for key, value in class_dict.items()\n",
    "]\n",
    "\n",
    "ordnance_labels = ordnance_labels + [\n",
    "    Line2D(\n",
    "        [0], [0], marker='s', color=\"w\", \n",
    "        markerfacecolor=f'C{int(key)}', markeredgecolor=f'C{int(key)}', \n",
    "        label=f\"true {class_dict[key]}\"\n",
    "    ) for key in [1, 2]\n",
    "]\n",
    "\n",
    "ax.plot(Y_profile[mnum_plot, :], D_profile[mnum_plot, :, :], '.', color=\"k\", alpha=0.3)\n",
    "ax.grid(\"both\", alpha=0.4)\n",
    "\n",
    "for i in range(net_data_profile.shape[0]):\n",
    "    y_plot = np.mean(net_y_profile[i, mnum_plot, :])\n",
    "    ax.plot(y_plot, 0, f'C{labels_profile[i]}o')\n",
    "\n",
    "txnumplot = sensor_table[mnum_plot, 0]\n",
    "rxnumplot = sensor_table[mnum_plot, 3]\n",
    "rxcompplot = sensor_table[mnum_plot, 2]\n",
    "ax.set_title(f\"Transmitter: {txnumplot}, Receiver: {rxnumplot}, {rxcompplot}-component\")\n",
    "ax.set_xlabel(\"along-line distance (m)\")\n",
    "\n",
    "for i in range(len(depths_profile)):\n",
    "    label = params_profile[\"label\"][i]\n",
    "    ax.plot(params_profile[\"y\"][i], -1, f\"sC{label}\")\n",
    "\n",
    "ax.legend(handles=ordnance_labels)\n",
    "\n",
    "# ax.set_xlim([-10, 0])\n",
    "ax.set_ylim([-2, 8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load up a line from the test site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../UXO_protected/data-blacktusk\"\n",
    "groundtruth = pd.read_excel(os.path.sep.join([data_directory, \"groundtruth_Testplot5F.xlsx\"]), nrows=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = pd.read_excel(os.path.sep.join([data_directory, \"groundtruth_Testplot5F.xlsx\"]), nrows=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5 functions\n",
    "def proc_attr(inp):\n",
    "    \"\"\"HDF5 - Process attributes for the input group and return them in a dictionary.\"\"\"\n",
    "    dic = {}\n",
    "    for att in inp.attrs.keys():\n",
    "        if inp.attrs[att].dtype.char == 'S':\n",
    "            dic[att] = [x.strip() for x in inp.attrs[att].tostring().decode('ascii').split(',')]\n",
    "        else:\n",
    "            dic[att] = inp.attrs[att][0] if isinstance(inp.attrs[att],np.ndarray) and inp.attrs[att].size==1 else inp.attrs[att]\n",
    "    return dic\n",
    "    pass\n",
    "\n",
    "def proc_group(inp):\n",
    "    \"\"\"HDF5 - A recursive function for reading datasets and attributes into a dictionary.\"\"\"\n",
    "    dic = {}\n",
    "    dic.update(proc_attr(inp))\n",
    "    for key in inp.keys():\n",
    "        if isinstance(inp[key], h5py.Group):\n",
    "            dic.update({key:proc_group(inp[key])})\n",
    "        else:\n",
    "            dic[key] = inp[key][()]\n",
    "        pass\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile = os.path.join(data_directory, 'Testplot5F.h5')\n",
    "f = h5py.File(dfile, 'r')\n",
    "dic = proc_group(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sensorinfo structure\n",
    "sensor_name = dic['SensorName'][0]\n",
    "sensor_config = dic['SensorConfig'][0]\n",
    "afile = os.path.join(code_dir,'config','sensor_definitions','{}___{}.yaml'.format(sensor_name,sensor_config))\n",
    "sensorinfo = SensorInfo.fromYAML(afile)[0]\n",
    "\n",
    "print(sensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_dict = dic[\"XYZ\"]\n",
    "ch = xyz_dict['Info']['ChannelNames']\n",
    "datai = xyz_dict['Info']['Data']['ChannelIndex'].flatten().astype(int)-1 # These are indices to the decay data\n",
    "yawi = int(xyz_dict['Info']['Yaw']['ChannelIndex'])-1 # index to the yaw channel\n",
    "mni = int(xyz_dict[\"Info\"][\"MeasNum\"][\"ChannelIndex\"])-1\n",
    "easting = int(xyz_dict[\"Info\"][\"Easting\"][\"ChannelIndex\"])-1\n",
    "northing = int(xyz_dict[\"Info\"][\"Northing\"][\"ChannelIndex\"])-1\n",
    "linesi = int(xyz_dict[\"Info\"][\"Line\"][\"ChannelIndex\"])-1\n",
    "rx_num = int(xyz_dict[\"Info\"][\"RxNum\"][\"ChannelIndex\"])-1\n",
    "tx_num = int(xyz_dict[\"Info\"][\"TxNum\"][\"ChannelIndex\"])-1\n",
    "rx_comp = int(xyz_dict[\"Info\"][\"RxCNum\"][\"ChannelIndex\"])-1\n",
    "rx_num = int(xyz_dict[\"Info\"][\"RxNum\"][\"ChannelIndex\"]) - 1\n",
    "\n",
    "times = np.array(dic['SensorTimes'].flatten())\n",
    "print(times.min(), times.max(), len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_data = xyz_dict[\"Data\"]\n",
    "mn = xyz_data[mni, :].astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_id = 1013 #, 1013]\n",
    "line_inds = xyz_data[linesi, :] == line_id\n",
    "print(sum(line_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(xyz_data[easting, line_inds], xyz_data[northing, line_inds], '.', alpha=0.1, ms=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local coordinates for the data set \n",
    "x0, y0 = np.mean(xyz_data[easting, :]), np.mean(xyz_data[northing, :])\n",
    "local_easting = xyz_data[easting, :] - x0\n",
    "local_northing = xyz_data[northing, :] - y0\n",
    "\n",
    "slope, intercept, _, _, _ = stats.linregress(local_easting, local_northing)\n",
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.arctan(slope)+np.pi/2\n",
    "local_x = np.cos(theta) * local_easting + np.sin(theta) * local_northing\n",
    "local_y = -np.sin(theta) * local_easting + np.cos(theta) * local_northing\n",
    "\n",
    "\n",
    "local_ground_truth_easting = np.array(groundtruth[\"Easting\"] - x0)\n",
    "local_ground_truth_northing = np.array(groundtruth[\"Northing\"] - y0)\n",
    "local_ground_truth_x = np.cos(theta) * local_ground_truth_easting + np.sin(theta) * local_ground_truth_northing\n",
    "local_ground_truth_y = -np.sin(theta) * local_ground_truth_easting + np.cos(theta) * local_ground_truth_northing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x = local_x[line_inds]\n",
    "line_y = local_y[line_inds]\n",
    "\n",
    "mn_line = mn[line_inds]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(line_x, line_y, '.', ms=0.1)\n",
    "ax.set_xlim(np.r_[-20, 20])\n",
    "ax.set_title(\"rotated coordinate system\")\n",
    "\n",
    "ax.plot(local_ground_truth_x, local_ground_truth_y, 'k.', label=\"ordnance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_inds_covered = (\n",
    "    (local_ground_truth_x >= line_x.min()) & (local_ground_truth_x <= line_x.max()) &\n",
    "    (local_ground_truth_y >= line_y.min()) & (local_ground_truth_y <= line_y.max())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_line = mn[line_inds]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 14))\n",
    "\n",
    "for plot_mn in range(11):\n",
    "\n",
    "    plot_inds = (mn_line==plot_mn)\n",
    "    ax.plot(line_x[plot_inds], line_y[plot_inds], '.', ms=1, label=plot_mn)\n",
    "\n",
    "ax.plot(\n",
    "    local_ground_truth_x[ord_inds_covered], local_ground_truth_y[ord_inds_covered], 'k.', label=\"ordnance\", ms=10\n",
    ")\n",
    "lgnd = ax.legend()\n",
    "[h._legmarker.set_markersize(6) for h in lgnd.legendHandles]\n",
    "\n",
    "ax.set_xlim([-12, -2])\n",
    "ax.set_ylim([-10, 10])\n",
    "ax.grid(\"both\", alpha = 0.4)\n",
    "ax.set_aspect(0.5)\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target data shape 165 X nlocs X nTimes \n",
    "# grab by measurement number \n",
    "# then re-stack\n",
    "\n",
    "x_locs = []\n",
    "y_locs = []\n",
    "data_list = []\n",
    "line_data = xyz_data[datai, :][:, line_inds]\n",
    "\n",
    "for mnind in range(mn.max() + 1):\n",
    "    mninds = mn_line == mnind\n",
    "    x_locs.append(line_x[mninds])\n",
    "    y_locs.append(line_y[mninds])\n",
    "    data_list.append(line_data[:, mninds].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(y_locs[0], data_list[0], '.', color=\"k\", alpha=0.3)\n",
    "ax.grid(\"both\", alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_locs = np.vstack(x_locs)\n",
    "Y_locs = np.vstack(y_locs)\n",
    "S_data = np.stack(data_list, axis=0)\n",
    "print(S_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = int(ymax/y_spacing)\n",
    "w_step = 5\n",
    "n_windows = (X_locs.shape[1]-window_width)//w_step + 1\n",
    "print(n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = S_data.shape\n",
    "net_data = np.zeros((n_windows, n[0], window_width, n[2]))\n",
    "net_y = np.zeros((n_windows, n[0], window_width))\n",
    "net_x = np.zeros((n_windows, n[0], window_width))\n",
    "\n",
    "for i in range(n_windows):\n",
    "    inds = slice(i*w_step,i*w_step+window_width)\n",
    "    net_x[i, :, :] = X_locs[:, inds]\n",
    "    net_y[i, :, :] = Y_locs[:, inds]\n",
    "    net_data[i, :, :, :] = S_data[:, inds, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_data_torch = torch.from_numpy(np.float32(net_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_field = net(net_data_torch, K, batch_norm)\n",
    "    n = W.shape\n",
    "    S = torch.matmul(out_field.view(-1, n[0]), W)\n",
    "    probs_field = functional.softmax(S, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels_field = torch.max(probs_field, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnum_plot = 1\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "ordnance_labels = [\n",
    "    Line2D(\n",
    "        [0], [0], marker='o', color=\"w\", \n",
    "        markerfacecolor=f'C{int(key)}', markeredgecolor=f'C{int(key)}', \n",
    "        label=value\n",
    "    ) for key, value in class_dict.items()\n",
    "]\n",
    "\n",
    "ordnance_labels.append(\n",
    "    Line2D(\n",
    "        [0], [0], marker='s', color=\"w\", \n",
    "        markerfacecolor=f'C3', markeredgecolor=f'C3', \n",
    "        label=\"ground truth\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ax.plot(y_locs[mnum_plot], data_list[mnum_plot], '.', color=\"k\", alpha=0.3)\n",
    "ax.grid(\"both\", alpha=0.4)\n",
    "\n",
    "for i in range(net_data.shape[0]):\n",
    "    y_plot = np.mean(net_y[i, mnum_plot, :])\n",
    "    ax.plot(y_plot, 0, f'C{labels_field[i]}o')\n",
    "\n",
    "txnumplot = sensor_table[mnum_plot, 0]\n",
    "rxnumplot = sensor_table[mnum_plot, 3]\n",
    "rxcompplot = sensor_table[mnum_plot, 2]\n",
    "ax.set_title(f\"Line: {line_id}, Transmitter: {txnumplot}, Receiver: {rxnumplot}, {rxcompplot}-component\")\n",
    "ax.set_xlabel(\"along-line distance (m)\")\n",
    "ax.plot(local_ground_truth_y[ord_inds_covered], -10*np.ones(ord_inds_covered.sum()), \"sC3\")\n",
    "\n",
    "ax.legend(handles=ordnance_labels)\n",
    "\n",
    "ax.set_xlim([0, 30])\n",
    "ax.set_ylim([-50, 50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth[\"ItemBuried\"][ord_inds_covered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth[\"Comment\"][ord_inds_covered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
